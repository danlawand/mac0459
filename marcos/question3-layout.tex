\documentclass[11221709.tex]{subfiles}

\begin{document}
    \textbf{Questão 3.}

    \begin{center}
        Dissertação sobre o artigo ``\textit{Misplaced Trust:
        Measuring the Interference of Machine Learning in Human
        Decision-Making}''
    \end{center}

    Não é incomum nos dias de hoje, encontrar sistemas capazes de
    realizar tarefas que, há não muito tempo atrás, seriam
    consideradas praticamente impossíves, ou muito difiíceis de
    serem realizadas por um computador, recebendo dados e fazendo
    predições sobre esses dados, mesmo não tendo sido diretamente
    programados para isso. Um exemplo é um sistema capaz de receber
    uma foto e classificar quais objetos estão presentes na mesma.
    Um outro exemplo é um sistema capaz de receber uma gravação de
    voz e classificar se o autor da gravação possui algum problema
    respiratório ou não. Sistemas como esse só são possíveis devido
    aos avanços na área de Aprendizado de Máquina, \textit{Machine
    Learning}, em inglês, e poderão ser de grande auxílio para a
    humanidade. Porém, assim como nós, esses sistemas são
    suscetíveis ao erro e cabe a nós, seres humanos, confiar ou não
    na classificação realizada para a tomada de decisão. O artigo
    aborda justamente este tema, como o Aprendizado de Máquina pode
    interferir na tomada de decisão humana, se o impacto é negativo,
    ou seja, nos leva a tomar decisões incorretas que acertaríamos
    sem interferência, ou se o impacto é positivo, aumentando a
    nossa capacidade de acerto.

    O estudo não visa apenas averiguar como as pessoas são afetadas
    pelas recomendações de um modelo na tomada de decisão, mas
    também como um conhecimento prévio de aprendizado de máquina, ou
    de matemática e lógica pode influenciar os resultados, e como a
    apresentação de uma explicação mais transparente sobre o modelo
    implementado impacta na nossa confiança. Para isso, foram
    criadas tarefas que avaliam os conhecimentos de cada
    participante em Matemática, Lógica e Aprendizado de Máquina.
    Também foram preparadas questões para medir como as
    recomendações de um modelo influenciam na tomada de decisão e um
    material explicativo sobre os modelos.

    As conclusões dos autores do estudo são de que os modelos
    impactam negativamente na tomada de decisão das pessoas. Os
    dados insinuam que, mesmo as pessoas sabendo que a recomendação
    do modelo não é tão confiável e tendo o conhecimento necessário
    para reconhecer isso, ainda assim a seguem, o que leva ao erro.
    Além disso, conhecimentos em matemática e lógica são igualmente
    importantes a conhecimentos em ML para as pessoas que são
    responsáveis por interpretar os resultados e pela tomada
    decisão.

    Um ponto positivo do estudo é a maneira como os autores pensaram
    bem na forma como seriam coletadas as informações. Montar as
    próprias questões para avaliar o nível de conhecimento de cada
    candidato foi uma decisão inteligente, pois é difícil esperar
    que as pessoas tenham a mesma noção do quanto sabem sobre
    determinado assunto. Isso permitiu aos autores ter uma boa noção
    relativa do conhecimento de cada pessoa, o que possibilita uma
    precisão maior ao separar os grupos de acordo com seus
    conhecimentos.

    Foi prudente também não fazer muitas questões e tentar manter os
    vídeos com o mínimo de informação possível para que a perda de
    interesse ou o cansaço não afetassem o desempenho dos
    candidatos.

    Outro ponto importante foi analisar não somente o impacto de um
    conhecimento prévio de \textit{Machine Learning}, mas também de
    Matemática e Lógica, porque se eventualmente for necessário
    selecionar alguém para desempenhar uma tarefa ao lado de um
    modelo, sabemos um bom critério para selecionar essa pessoa ou
    até mesmo quais assuntos ensinar, se existir a possibilidade de
    oferecer um curso preparatório para quem fica responsável por
    trabalhar junto do modelo.

    Um ponto negativo no estudo é que, como os dados foram coletados
    de forma remota, é difícil assegurar com toda a certeza que os
    dados não possam ter sido adulterados de alguma forma. Por
    exemplo, ainda que os vídeos tivessem curta duração e, em algum
    momento, era obrigatório que todos os minutos fossem assistidos,
    não é possível garantir que foram realmente assistidos, e, mesmo
    que tenham sido assistidos, não dá para garantir que a
    informação foi devidamente retida. Assim, é difícil garantir que
    todos os candidatos que assistiram aos vídeos explicativos
    entenderam corretamente o que foi dito e como utilizar esse
    conhecimento para confiar mais ou menos nas recomendações do
    algoritmo.

    Outro ponto negativo no estudo é a quantidade e variedade dos
    dados coletados. No total, participaram 175 candidatos, porém, a
    maioria desses candidatos é da etnia branca e a maioria dos
    candidatos estava na faixa etária dos 18 aos 24 anos, sendo mais
    da metade com idade inferior a 34 anos. Seria interessante, por
    exemplo, saber se a mesma tendência pode ser observada quando o
    público considerado é de gerações mais antigas. Ou talvez saber
    se pessoas de diferentes países também seguem essa mesma
    tendência.

    Um último detalhe que gostaria de apontar em relação ao estudo é
    sobre as tarefas escolhidas para serem recomendadas por modelos
    de Aprendizado de Máquina. Foi interessante ter visto como
    nessas tarefas mais gerais, em que temos alguma intuição, mas
    ainda são difíceis, a conclusão é de que os modelos podem
    diminuir nossa precisão. De acordo com o autor, essas escolhas
    foram pensadas justamente para que as pessoas pudessem
    considerar as recomendações feitas pelo modelo. Porém, em geral,
    é razoável assumir que as pessoas responsáveis pela tomada de
    decisões importantes possuem alguma capacitação prévia na tarefa
    que estão executando e, nesse caso, provavelmente muito mais
    confiança nas suas próprias recomendações do que em comparação
    com pessoas que não estão capacitadas especificamente para a
    tarefa. Nesse caso, seria interessante buscar compreender também
    se nessas situações há uma confiança prejudicial no modelo, ou
    se o modelo de fato leva a uma melhora no acerto. Um exemplo
    seriam oncologistas analisando imagens e classificando se pode
    ou não ser um tumor, um classificador poderia auxiliar a
    aumentar a precisão na identificação.
    % Planejamento:

    % Depois do resumo (acho que isso toma uma meia página pelo
    % menos) começar a organizar meus argumentos. O que eu
    % gostei no estudo?

    % Gostei do fato deles terem montado as próprias questões e
    % também da maneira como eles restringiram os estados entre os 
    %
    % O que eu não gostei no estudo?
    % - Falha na maneira como os dados foram coletados, é possível
    %   burlar o sistema de algumas maneiras pelo fato de ser
    %   remoto, idealmente deveria ser presencial
    % - Um ponto que penso que discordo é o fato dos testes
    %   terem sido feitos sem um propósito definido, é difícil
    %   generalizar algo do tipo, qual é a conclusão correta
    %   quando as pessoas envolvidas são profissionais na área?

    % A quantidade de pessoas é suficiente? Apenas nível de
    % educação deveria ser levado em conta?
    % O mesmo pode ser observado em diferentes países?
\end{document}